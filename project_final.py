# -*- coding: utf-8 -*-
"""Project Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hr9FhhdWFQi41jfIkXTZy78R1ks_51wK

# Breast Cancer Detection
## Preprocessing (feature extraction, standardization, and nonlinear transformation)
"""

from google.colab import drive
drive.mount('/content/drive')

from sklearn import preprocessing
from sklearn import metrics
import numpy as np
import pandas as pd
from sklearn import linear_model
from sklearn import metrics
import matplotlib

# import data as pandas dataframe
df = pd.read_csv('/content/sample_data/Breast_cancer_data.csv')
data = df.to_numpy()
features = list(df.columns[:-1])
print(df.columns)
# separate training data (x) from label (y)
df_y = df[['diagnosis']]
print(df_y)
df_x = df[['mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area', 'mean_smoothness']]
print(df_x)

"""#Data Preprocessing: Standardization"""

# standardize training data (x)
df_x = (df_x - df_x.mean())/df_x.std()
print(df)

"""# Ridge Regression Classification"""

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold

# Use ridge regression to predict values of y
reg = linear_model.Ridge(alpha=0.5)
reg.fit(df_x, df_y)
yhat = reg.predict(df_x)
# print('yhat: ', yhat)

"""##Quantitative Metrics - MSE, RMSE"""

#calculate MSE
mse = metrics.mean_squared_error(df_y, yhat)
print('mse: ', mse)
#calculate RMSE
rmse = np.sqrt(mse)
print('rmse ', rmse)

"""##Cross Validation: Finding Optimal Alpha"""

# Generate 100 possible alpha values between 0 and 5
alphas_to_try = np.logspace(0, 5, 100)

# cross validate over each alpha, finding the best model based on mse
best_model = linear_model.RidgeCV(alphas=alphas_to_try, scoring='neg_mean_squared_error')

# rerun regression on our data using the best alpha
best_model.fit(df_x, df_y)
print('alpha_chosen: ', best_model.alpha_)
yhat_best = best_model.predict(df_x)


#calculate new mse, rmse values
#calculate MSE
best_mse = metrics.mean_squared_error(df_y, yhat_best)
print('mse: ', best_mse)
#calculate RMSE
best_rmse = np.sqrt(best_mse)
print('rmse: ', best_rmse)

"""## Visualisation"""

from matplotlib import pyplot as plt
plt.scatter(yhat, df_y - yhat, color='blue', alpha=0.6)
plt.axhline(y=0, color='red', linestyle='--')
plt.title('Residual Plot (Training Set)')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.grid(True)

#Exploration
import seaborn as sns
plt.figure(figsize = (10, 10))
sns.heatmap(df.corr(), annot = True)
plt.show()

plt.figure(figsize=(12, 8))
plt.plot(reg.coef_.T, marker='o', linestyle='-', color='b', label='Ridge Regression Coefficients')
plt.xlabel('Feature Index')
plt.ylabel('Coefficient Value')
plt.title('Ridge Regression Coefficients')
plt.legend()
plt.grid(True)
plt.xticks(range(5), features)
plt.tight_layout()
plt.show()

# Plotting predicted vs. actual values
plt.figure(figsize=(10, 8))
plt.scatter(df_y, yhat, color='blue', label=f'Predicted values, RMSE={rmse:.2f}')
#plt.plot([min(df_y), max(df_y)], [min(yhat), max(yhat)], linestyle='--', color='red')
plt.xlabel('Actual values')
plt.ylabel('Predicted values')
plt.title('Actual vs Predicted values (Ridge Regression)')
plt.legend()
plt.grid(True)
plt.show()

# import matplotlib.pyplot as plt
# plt.scatter(df['mean_radius'], df['diagnosis'], color='blue', label='Mean Radius vs Diagnosis')
# #plt.scatter(df['mean_texture'], df['diagnosis'], color='red', label='Mean Texture vs Diagnosis')
# plt.scatter(df['mean_perimeter'], df['diagnosis'], color='green', label='Mean Perimeter vs Diagnosis')
# plt.scatter(df['mean_area'], df['diagnosis'], color='pink', label='Mean Area vs Diagnosis')
# #plt.scatter(df['mean_smoothness'], df['diagnosis'], color='yellow', label='Mean Smoothness vs Diagnosis')

# plt.xlabel('Features')
# plt.ylabel('Diagnosis')
# plt.legend()
# plt.title('Data Points and Prediction Visualization')
# plt.show()

"""# Data Preprocessing: Principle Component Analysis"""

from sklearn.decomposition import PCA

# Reduce from 5 features to 3 features
pca = PCA(n_components=3)
reduced_x = pca.fit_transform(df_x)
df_pca_x = pd.DataFrame(reduced_x, columns=['Principle Component 1', 'Principle Component 2','Principle Component 3'])
print(df_pca_x)

from sklearn.decomposition import PCA

# Reduce from 5 features to 2 features
pca = PCA(n_components=2)
reduced_x = pca.fit_transform(df_x)
df_pca_x = pd.DataFrame(reduced_x, columns=['Principle Component 1', 'Principle Component 2'])
print(df_pca_x)

"""# Logistic Regression w/o PCA"""

# Import necessary libraries
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Run logistic regresion w/o PCA first
# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(df_x, df_y.values.ravel(), test_size=0.2)

# run logistic regression model
log_reg = LogisticRegression()
log_reg.fit(x_train, y_train)

# Make predictions on the test set
y_pred = log_reg.predict(x_test)

"""# Logistic Regression w/ PCA"""

# Run logistic regresion w/ PCA
# Split the data into training and testing sets
x_train_pca, x_test_pca, y_train_pca, y_test_pca = train_test_split(df_pca_x, df_y.values.ravel(), test_size=0.2)

# run logistic regression model
log_reg = LogisticRegression()
log_reg.fit(x_train_pca, y_train_pca)

# Make predictions on the test set
y_pred_pca = log_reg.predict(x_test_pca)

"""## Quantitative Metrics - Accuracy, Confusion Matrix, Classification Report for Logistic Regression"""

# Evaluate the model without PCA
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

# Print the evaluation results
print(f'Accuracy: {accuracy}')
print('Confusion Matrix:')
print(conf_matrix)
print('Classification Report:')
print(class_report)

# Evaluate the model with PCA
accuracy_withpca = accuracy_score(y_test_pca, y_pred_pca)
conf_matrix_withpca = confusion_matrix(y_test_pca, y_pred_pca)
class_report_withpca = classification_report(y_test_pca, y_pred_pca)

# Print the evaluation results
print(f'Accuracy with PCA: {accuracy_withpca}')
print('Confusion Matrix with PCA:')
print(conf_matrix_withpca)
print('Classification Report with PCA:')
print(class_report_withpca)

"""##Visualisation"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve
# Predict probabilities on the test set
y_prob_pca = log_reg.predict_proba(x_test_pca)[:, 1]
# Compute ROC curve
fpr, tpr, _ = roc_curve(y_test_pca, y_prob_pca)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic with PCA')
plt.legend(loc='lower right')
plt.show()

# Compute precision-recall curve
precision, recall, _ = precision_recall_curve(y_test_pca, y_prob_pca)
rp_auc = auc(recall, precision)
# Plot precision-recall curve
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='b', lw=2, label=f'Precision-Recall curve (area = {rp_auc:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve with PCA')
plt.legend(loc='lower left')
plt.show()

"""## Visualization w/ PCA 2 components"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification

x_min, x_max = x_train_pca.iloc[:, 0].min() - 1, x_train_pca.iloc[:, 0].max() + 1
y_min, y_max = x_train_pca.iloc[:, 1].min() - 1, x_train_pca.iloc[:, 1].max() + 1

# Create a mesh grid
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),
                     np.arange(y_min, y_max, 0.01))

# Predict the class for each point in the mesh grid
Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Plot the decision boundary
plt.figure(figsize=(10, 6))
plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)
plt.scatter(x_train_pca.iloc[:, 0], x_train_pca.iloc[:, 1], c=y_train_pca, edgecolor='k', marker='o', s=50, cmap=plt.cm.Paired)
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.title('Decision Boundary for Logistic Regression')
plt.colorbar()
plt.show()

import seaborn as sns
from sklearn.metrics import confusion_matrix

# Confusion Matrix for RBF Kernel
cm_rbf = confusion_matrix(y_test_pca, y_pred_rbf_pca)
sns.heatmap(cm_rbf, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for RBF Kernel')
plt.show()

def plot_decision_function(X, y, model, title):
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                         np.arange(y_min, y_max, 0.02))

    Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    plt.figure(figsize=(8, 6))
    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', marker='o', s=50, cmap=plt.cm.Paired)
    plt.xlabel('PCA Component 1')
    plt.ylabel('PCA Component 2')
    plt.title(title)
    plt.colorbar()
    plt.show()

# Plot for RBF Kernel
plot_decision_function(X_train_pca, y_train_pca, ksvm_rbf_pca, 'Decision Function for RBF Kernel')

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Example DataFrames
df_pca_x = pd.DataFrame(X_train_pca, columns=['PCA1', 'PCA2'])  # X_train_pca should be your 2D PCA output
df_y = pd.DataFrame(y_train_pca, columns=['Label'])  # y_train_pca should be your labels

# Combine PCA components and labels into a single DataFrame
df_combined = pd.concat([df_pca_x, df_y], axis=1)

# Create pairplot
pairplot = sns.pairplot(df_combined, hue='Label', palette='viridis')
pairplot.fig.suptitle('Pairwise Plot of PCA Components', y=1.02)
plt.show()

"""# Support Vector Machine w/o PCA"""

# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import GridSearchCV
from sklearn import svm
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(df_x, df_y.values.flatten(), test_size=0.2, random_state=42)

# Scale the features using standardization
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


# --------
# RBF
# --------

# Create a kernel support vector machine model
ksvm_rbf = svm.SVC(kernel='rbf',
               gamma=0.001,
               C=10.0)

# Train the model on the training data
ksvm_rbf.fit(X_train, y_train)

# Make predictions on test set
y_pred_rbf = ksvm_rbf.predict(X_test)



# --------
# LINEAR
# --------

# Create a kernel support vector machine model
ksvm_lin = svm.SVC(kernel='linear',
               gamma=0.001,
               C=10.0)

# Train the model on the training data
ksvm_lin.fit(X_train, y_train)

# Make predictions on test set
y_pred_lin = ksvm_lin.predict(X_test)



# --------
# POLYNOMIAL
# --------

# Create a kernel support vector machine model
ksvm_poly = svm.SVC(kernel='poly',
               gamma=1,
               C=10.0)

# Train the model on the training data
ksvm_poly.fit(X_train, y_train)

# Make predictions on test set
y_pred_poly = ksvm_poly.predict(X_test)



# --------
# SIGMOID
# --------

# Create a kernel support vector machine model
ksvm_sig = svm.SVC(kernel='sigmoid',
               gamma=0.001,
               C=13.0)

# Train the model on the training data
ksvm_sig.fit(X_train, y_train)

# Make predictions on test set
y_pred_sig = ksvm_sig.predict(X_test)

"""## Quantitative Metrics - Accuracies, Confusion Matrix, and Classification Report (F1-score) for SVM (w/o PCA)"""

# RBF Stats
accuracy_rbf = ksvm_rbf.score(X_test, y_test)
print('RBF Accuracy:', accuracy_rbf)
conf_matrix_rbf = confusion_matrix(y_test, y_pred_rbf)
print('Confusion Matrix for RBF: ')
print(conf_matrix_rbf)
class_report_rbf = classification_report(y_test, y_pred_rbf)
print('Classification Report for RBF:')
print(class_report_rbf)

# Linear Stats
accuracy_lin = ksvm_lin.score(X_test, y_test)
print('Linear Accuracy:', accuracy_lin)
conf_matrix_lin = confusion_matrix(y_test, y_pred_lin)
print('Confusion Matrix for Linear: ')
print(conf_matrix_lin)
class_report_lin = classification_report(y_test, y_pred_lin)
print('Classification Report for Linear:')
print(class_report_lin)

# Polynomial Stats
accuracy_poly = ksvm_poly.score(X_test, y_test)
print('Polynomial Accuracy:', accuracy_poly)
conf_matrix_poly = confusion_matrix(y_test, y_pred_poly)
print('Confusion Matrix for Polynomial: ')
print(conf_matrix_poly)
class_report_poly = classification_report(y_test, y_pred_poly)
print('Classification Report for Polynomial:')
print(class_report_poly)

# Sigmoid Stats
accuracy_sig = ksvm_sig.score(X_test, y_test)
print('Sigmoid Accuracy:', accuracy_sig)
conf_matrix_sig = confusion_matrix(y_test, y_pred_sig)
print('Confusion Matrix for Sigmoid: ')
print(conf_matrix_sig)
class_report_sig = classification_report(y_test, y_pred_sig)
print('Classification Report for Sigmoid:')
print(class_report_sig)

"""##Visualization"""

from sklearn.metrics import roc_curve, auc, precision_recall_curve
from sklearn.preprocessing import label_binarize
import matplotlib.pyplot as plt
# Get decision function scores
y_score = ksvm_rbf.decision_function(X_test)

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(12, 6))

# ROC Curve Plot
plt.subplot(1, 2, 1)
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('SVM-RBF: Receiver Operating Characteristic')
plt.legend(loc='lower right')

# Precision-Recall Curve Plot
precision, recall, _ = precision_recall_curve(y_test, y_score)
rp_auc = auc(recall, precision)

plt.subplot(1, 2, 2)
plt.plot(recall, precision, color='b', lw=2, label=f'Precision-Recall curve (area = {rp_auc:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('SVM-RBF:Precision-Recall Curve')
plt.legend(loc='lower left')

plt.tight_layout()
plt.show()

# Get decision function scores
y_score = ksvm_lin.decision_function(X_test)

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(12, 6))

# ROC Curve Plot
plt.subplot(1, 2, 1)
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('SVM-Linear: Receiver Operating Characteristic')
plt.legend(loc='lower right')

# Precision-Recall Curve Plot
precision, recall, _ = precision_recall_curve(y_test, y_score)
rp_auc = auc(recall, precision)

plt.subplot(1, 2, 2)
plt.plot(recall, precision, color='b', lw=2, label=f'Precision-Recall curve (area = {rp_auc:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('SVM-Linear:Precision-Recall Curve')
plt.legend(loc='lower left')

plt.tight_layout()
plt.show()

# Get decision function scores
y_score = ksvm_poly.decision_function(X_test)

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(12, 6))

# ROC Curve Plot
plt.subplot(1, 2, 1)
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('SVM-Polynomial: Receiver Operating Characteristic')
plt.legend(loc='lower right')

# Precision-Recall Curve Plot
precision, recall, _ = precision_recall_curve(y_test, y_score)
rp_auc = auc(recall, precision)

plt.subplot(1, 2, 2)
plt.plot(recall, precision, color='b', lw=2, label=f'Precision-Recall curve (area = {rp_auc:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('SVM-Polynomial:Precision-Recall Curve')
plt.legend(loc='lower left')

plt.tight_layout()
plt.show()



# Get decision function scores
y_score = ksvm_sig.decision_function(X_test)

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(12, 6))

# ROC Curve Plot
plt.subplot(1, 2, 1)
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('SVM-Sigmoid: Receiver Operating Characteristic')
plt.legend(loc='lower right')

# Precision-Recall Curve Plot
precision, recall, _ = precision_recall_curve(y_test, y_score)
rp_auc = auc(recall, precision)

plt.subplot(1, 2, 2)
plt.plot(recall, precision, color='b', lw=2, label=f'Precision-Recall curve (area = {rp_auc:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('SVM-Sigmoid:Precision-Recall Curve')
plt.legend(loc='lower left')

plt.tight_layout()
plt.show()

"""# Support Vector Machine w/ PCA"""

# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import GridSearchCV
from sklearn import svm
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(df_pca_x, df_y.values.flatten(), test_size=0.2, random_state=42)

# Scale the features using standardization
scaler = StandardScaler()
X_train_pca = scaler.fit_transform(X_train_pca)
X_test_pca = scaler.transform(X_test_pca)


# --------
# RBF
# --------

# Create a kernel support vector machine model
ksvm_rbf_pca = svm.SVC(kernel='rbf',
               gamma=0.001,
               C=10.0)

# Train the model on the training data
ksvm_rbf_pca.fit(X_train_pca, y_train_pca)

# Make predictions on test set
y_pred_rbf_pca = ksvm_rbf_pca.predict(X_test_pca)



# --------
# LINEAR
# --------

# Create a kernel support vector machine model
ksvm_lin_pca = svm.SVC(kernel='linear',
               gamma=0.001,
               C=10.0)

# Train the model on the training data
ksvm_lin_pca.fit(X_train_pca, y_train_pca)

# Make predictions on test set
y_pred_lin_pca = ksvm_lin_pca.predict(X_test_pca)



# --------
# POLYNOMIAL
# --------

# Create a kernel support vector machine model
ksvm_poly_pca = svm.SVC(kernel='poly',
               gamma=1,
               C=10.0)

# Train the model on the training data
ksvm_poly_pca.fit(X_train_pca, y_train_pca)

# Make predictions on test set
y_pred_poly_pca = ksvm_poly_pca.predict(X_test_pca)



# --------
# SIGMOID
# --------

# Create a kernel support vector machine model
ksvm_sig_pca = svm.SVC(kernel='sigmoid',
               gamma=0.001,
               C=13.0)

# Train the model on the training data
ksvm_sig_pca.fit(X_train_pca, y_train_pca)

# Make predictions on test set
y_pred_sig_pca = ksvm_sig_pca.predict(X_test_pca)

"""## Quantitative Metrics - Accuracies, Confusion Matrix, and Classification Report (F1-score) for SVM (w/ PCA)"""

# RBF Stats
accuracy_rbf_pca = ksvm_rbf_pca.score(X_test_pca, y_test_pca)
print('RBF Accuracy:', accuracy_rbf_pca)
conf_matrix_rbf_pca = confusion_matrix(y_test_pca, y_pred_rbf_pca)
print('Confusion Matrix for RBF w/ PCA: ')
print(conf_matrix_rbf_pca)
class_report_rbf_pca = classification_report(y_test_pca, y_pred_rbf_pca)
print('Classification Report for RBF:')
print(class_report_rbf_pca)

# Linear Stats
accuracy_lin_pca = ksvm_lin_pca.score(X_test_pca, y_test_pca)
print('Linear Accuracy w/ PCA:', accuracy_lin_pca)
conf_matrix_lin_pca = confusion_matrix(y_test_pca, y_pred_lin_pca)
print('Confusion Matrix for Linear w/ PCA: ')
print(conf_matrix_lin_pca)
class_report_lin_pca = classification_report(y_test_pca, y_pred_lin_pca)
print('Classification Report for Linear w/ PCA:')
print(class_report_lin_pca)

# Polynomial Stats
accuracy_poly_pca = ksvm_poly_pca.score(X_test_pca, y_test_pca)
print('Polynomial Accuracy w/ PCA:', accuracy_poly_pca)
conf_matrix_poly_pca = confusion_matrix(y_test_pca, y_pred_poly_pca)
print('Confusion Matrix for Polynomial w/ PCA: ')
print(conf_matrix_poly_pca)
class_report_poly_pca = classification_report(y_test_pca, y_pred_poly_pca)
print('Classification Report for Polynomial w/ PCA:')
print(class_report_poly_pca)

# Sigmoid Stats
accuracy_sig_pca = ksvm_sig_pca.score(X_test_pca, y_test_pca)
print('Sigmoid Accuracy w/ PCA:', accuracy_sig_pca)
conf_matrix_sig_pca = confusion_matrix(y_test_pca, y_pred_sig_pca)
print('Confusion Matrix for Sigmoid w/ PCA: ')
print(conf_matrix_sig_pca)
class_report_sig_pca = classification_report(y_test_pca, y_pred_sig_pca)
print('Classification Report for Sigmoid w/ PCA:')
print(class_report_sig_pca)

"""## Visualization w/ PCA 2 components"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from mpl_toolkits.mplot3d import Axes3D

# Assuming X_train_pca and X_test_pca are already 2D from PCA
def plot_decision_boundary(X, y, model, title):
    # Create a mesh grid based on the feature range
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                         np.arange(y_min, y_max, 0.02))

    # Get decision boundary
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    # Plot decision boundary
    plt.figure(figsize=(8, 6))
    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', marker='o', s=50, cmap=plt.cm.Paired)
    plt.xlabel('PCA Component 1')
    plt.ylabel('PCA Component 2')
    plt.title(title)
    plt.show()

# Plot for RBF Kernel
plot_decision_boundary(X_train_pca, y_train_pca, ksvm_rbf_pca, 'SVM with RBF Kernel')

# Plot for Linear Kernel
plot_decision_boundary(X_train_pca, y_train_pca, ksvm_lin_pca, 'SVM with Linear Kernel')

# Plot for Polynomial Kernel
plot_decision_boundary(X_train_pca, y_train_pca, ksvm_poly_pca, 'SVM with Polynomial Kernel')

# Plot for Sigmoid Kernel
plot_decision_boundary(X_train_pca, y_train_pca, ksvm_sig_pca, 'SVM with Sigmoid Kernel')

import seaborn as sns
from sklearn.metrics import confusion_matrix

# Confusion Matrix for RBF Kernel
cm_rbf = confusion_matrix(y_test_pca, y_pred_rbf_pca)
sns.heatmap(cm_rbf, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for RBF Kernel')
plt.show()

def plot_decision_function(X, y, model, title):
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                         np.arange(y_min, y_max, 0.02))

    Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    plt.figure(figsize=(8, 6))
    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', marker='o', s=50, cmap=plt.cm.Paired)
    plt.xlabel('PCA Component 1')
    plt.ylabel('PCA Component 2')
    plt.title(title)
    plt.colorbar()
    plt.show()

# Plot for RBF Kernel
plot_decision_function(X_train_pca, y_train_pca, ksvm_rbf_pca, 'Decision Function for RBF Kernel')

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Example DataFrames
df_pca_x = pd.DataFrame(X_train_pca, columns=['PCA1', 'PCA2'])  # X_train_pca should be your 2D PCA output
df_y = pd.DataFrame(y_train_pca, columns=['Label'])  # y_train_pca should be your labels

# Combine PCA components and labels into a single DataFrame
df_combined = pd.concat([df_pca_x, df_y], axis=1)

# Create pairplot
pairplot = sns.pairplot(df_combined, hue='Label', palette='viridis')
pairplot.fig.suptitle('Pairwise Plot of PCA Components', y=1.02)
plt.show()